{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 그라디언트 소실과 폭주문제\n",
    "\n",
    "- 활성화 함수 문제 : 로지스틱 함수는 입력의 절댓값이 커지면 0 또는 1로 수렴하게 되고 그렇게 되면 그레디언트가 0으로 된다. 그래서 역전파가 될 때 아래층으로 갈 수록 그레디언트가 전달 되지 않는다.\n",
    "- 초기화 방식 : 각층에서 출력의 분산이 입력의 분산보다 커지면서 위쪽 층으로 갈 수록 분산이 계속 증가하게 되어 활성화 함수의 값이 0 or 1 수렴"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.1 글로럿과 He 초기화\n",
    "- 초기화 방식에서 $n_{in}$ 과 $n_{out}$ 같으면 분산이 동일하게 됨 (여기서 $n_{in}$은 입력 뉴런의 수, $n_{out}$은 출력 뉴런의 수)\n",
    "- 만약 그렇지 않다면 각 층의 연결 가중치를 무작위로 초기화 함\n",
    "- 글로럿 초기화\n",
    "  - 균등 분포(Uniform distribution) : $W \\sim U[-\\sqrt{\\frac{6}{n_{in}+n_{out}}}, \\sqrt{\\frac{6}{n_{in}+n_{out}}}]$\n",
    "  - 정규 분포(Normal distribution) : $W \\sim N(0, \\frac{2}{n_{in}+n_{out}})$\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 초기화 방법                     | 분포                             | 설명                                                         |\n",
    "| ------------------------------- | -------------------------------- | ------------------------------------------------------------ |\n",
    "| 균등 분포(Uniform distribution) | $U[-\\text{limit}, \\text{limit}]$ | 무작위로 균등하게 초기화합니다. $\\text{limit}$ 값은 $sqrt(\\frac{6}{n_{in}+n_{out}})$과 같습니다. |\n",
    "| 정규 분포(Normal distribution)  | $N(\\mu, \\sigma)$                 | 무작위로 정규 분포를 따르는 값으로 초기화합니다. $\\mu$는 0이고, $\\sigma$값은 $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$과 같습니다. |\n",
    "| 르쿤(Lecun) 초기화              | $N(0, \\frac{1}{n_{in}})$         | ReLU나 SeLU와 같이 대칭이 아닌 활성화 함수를 사용할 때 적합합니다. |\n",
    "| 글로럿(Glorot) 초기화           | $U[-\\text{limit}, \\text{limit}]$ | 하이퍼볼릭 탄젠트나 시그모이드와 같은 S자 모양의 활성화 함수를 사용할 때 적합합니다. $\\text{limit}$ 값은 $sqrt(\\frac{6}{n_{in}+n_{out}})$과 같습니다. |\n",
    "| 해밍(Hamming) 초기화            | $U[-\\text{limit}, \\text{limit}]$ | 이진(binary) 분류 문제와 같이 범주형(categorical) 데이터셋에서 사용됩니다. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x22605f011e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x22605f00eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.2 수렴하지 않는 활성화 함수\n",
    "1. ReLU(Rectified Linear Unit) 함수 : 0이하의 값을 모두 0으로 출력 , 연산이 빠르지만 가중치의 합이 음수이면 기울기가 0이 되는 문제 발생\n",
    "2. Leaky ReLU 함수 : 입력값이 0이하의 값일때 작은 양수 값을 유지 , 죽은 Relu문제 해결\n",
    "3. ELU(Exponential Linear Unit) 함수 : 지수함수를 이용하여 그레디언트 소실 문제 해결 , 그러나 연산이 느림\n",
    "4. SELU(Scaled Exponential Linear Unit) 함수 : 자기 정규화를 수행\n",
    "5. ReLU의 변형 함수(PReLU, RReLU, LReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full,y_train_full) , (X_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.\n",
    "X_valid , X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid , y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape = [28,28]),\n",
    "        keras.layers.Dense(300,kernel_initializer = \"he_normal\"),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(100,kernel_initializer = \"he_normal\"),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "         keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.3210 - accuracy: 0.6039 - val_loss: 0.8871 - val_accuracy: 0.7166\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.7941 - accuracy: 0.7423 - val_loss: 0.7059 - val_accuracy: 0.7702\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6768 - accuracy: 0.7781 - val_loss: 0.6396 - val_accuracy: 0.7890\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6170 - accuracy: 0.7973 - val_loss: 0.5841 - val_accuracy: 0.8100\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5789 - accuracy: 0.8080 - val_loss: 0.5534 - val_accuracy: 0.8162\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5519 - accuracy: 0.8153 - val_loss: 0.5313 - val_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5314 - accuracy: 0.8200 - val_loss: 0.5128 - val_accuracy: 0.8308\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5156 - accuracy: 0.8241 - val_loss: 0.5058 - val_accuracy: 0.8328\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5029 - accuracy: 0.8262 - val_loss: 0.4884 - val_accuracy: 0.8384\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4918 - accuracy: 0.8307 - val_loss: 0.4805 - val_accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=1.05, alpha=1.67):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.95\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.90\n",
      "Layer 400: mean 0.05, std deviation 0.87\n",
      "Layer 500: mean -0.00, std deviation 0.92\n",
      "Layer 600: mean 0.03, std deviation 0.91\n",
      "Layer 700: mean -0.02, std deviation 0.89\n",
      "Layer 800: mean 0.05, std deviation 0.81\n",
      "Layer 900: mean 0.02, std deviation 0.99\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # 표준화된 입력\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun 초기화\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.3 배치정규화\n",
    "1. 미니배치에서 입력값의 평균과 분산을 계산합니다.\n",
    "   - 입력값의 각 차원마다 평균과 분산을 계산합니다.\n",
    "   - 이 때, 미니배치 내 모든 샘플에 대한 평균과 분산을 계산합니다.\n",
    "   - 따라서, 평균과 분산을 계산하는 과정은 입력값의 각 차원마다 독립적으로 이루어집니다.\n",
    "2. 평균과 분산을 사용하여 입력값을 정규화합니다.\n",
    "   - 각 차원마다 정규화합니다.\n",
    "   - 정규화된 입력값을 $\\hat{x}$ 라고 합니다.\n",
    "   - $\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$ (epsilon은 작은 값을 더해 분모가 0이 되는 것을 방지합니다)\n",
    "3. 정규화된 입력값에 대해 스케일과 시프트를 적용합니다.\n",
    "   - 학습 가능한 파라미터인 gamma와 beta를 사용합니다.\n",
    "   - gamma는 스케일을, beta는 시프트를 나타냅니다.\n",
    "   - 정규화된 입력값에 각각 gamma와 beta를 곱하고 더합니다.\n",
    "   - 최종적으로, $y = \\gamma \\hat{x} + \\beta$ 가 됩니다.\n",
    "4. 정규화된 입력값에 스케일과 시프트를 적용한 결과를 활성화 함수로 전달합니다.\n",
    "   - 활성화 함수로는 ReLU나 sigmoid 등을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8534 - accuracy: 0.7122 - val_loss: 0.5551 - val_accuracy: 0.8090\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5755 - accuracy: 0.8008 - val_loss: 0.4750 - val_accuracy: 0.8382\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5177 - accuracy: 0.8184 - val_loss: 0.4407 - val_accuracy: 0.8468\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4795 - accuracy: 0.8327 - val_loss: 0.4159 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4535 - accuracy: 0.8408 - val_loss: 0.4007 - val_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4370 - accuracy: 0.8461 - val_loss: 0.3879 - val_accuracy: 0.8630\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4229 - accuracy: 0.8527 - val_loss: 0.3771 - val_accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4106 - accuracy: 0.8551 - val_loss: 0.3695 - val_accuracy: 0.8684\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4014 - accuracy: 0.8593 - val_loss: 0.3637 - val_accuracy: 0.8686\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3883 - accuracy: 0.8621 - val_loss: 0.3581 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#활성화 함수 전에 배치 정규화 층을 추가하려면 은닉층에서 활성화 함수를 지정하지 말고 배치 정규화 층 뒤에 별도의 층으로 추가해야 함\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0371 - accuracy: 0.6753 - val_loss: 0.6654 - val_accuracy: 0.7864\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6736 - accuracy: 0.7789 - val_loss: 0.5486 - val_accuracy: 0.8214\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5944 - accuracy: 0.8010 - val_loss: 0.4959 - val_accuracy: 0.8366\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5427 - accuracy: 0.8171 - val_loss: 0.4632 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5106 - accuracy: 0.8264 - val_loss: 0.4415 - val_accuracy: 0.8506\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4890 - accuracy: 0.8315 - val_loss: 0.4238 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4707 - accuracy: 0.8382 - val_loss: 0.4116 - val_accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4575 - accuracy: 0.8419 - val_loss: 0.4019 - val_accuracy: 0.8572\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4455 - accuracy: 0.8460 - val_loss: 0.3925 - val_accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4325 - accuracy: 0.8499 - val_loss: 0.3857 - val_accuracy: 0.8614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 \n",
    "- momentum : 지수이동평균에서 쓰이는 파라메터, 데이터셋이 크고 미니배치가 작으면 1에 더 가깝게 함\n",
    "- axis : 마지막 축을 정규화 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1.4 그레이디언트 클리핑\n",
    "- clipvalue or clipnorm 중에 지정하여 클리핑 할 수 있다.\n",
    "- 일반적으로 배치 정규화면 충분함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 사전훈련된 층 재사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.5993 - accuracy: 0.8015 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3240 - val_accuracy: 0.8834\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3180 - accuracy: 0.8906 - val_loss: 0.2968 - val_accuracy: 0.8976\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2976 - accuracy: 0.8978 - val_loss: 0.2812 - val_accuracy: 0.9026\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2843 - accuracy: 0.9026 - val_loss: 0.2706 - val_accuracy: 0.9056\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2744 - accuracy: 0.9065 - val_loss: 0.2683 - val_accuracy: 0.9058\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2663 - accuracy: 0.9098 - val_loss: 0.2653 - val_accuracy: 0.9091\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2597 - accuracy: 0.9125 - val_loss: 0.2595 - val_accuracy: 0.9093\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2543 - accuracy: 0.9141 - val_loss: 0.2515 - val_accuracy: 0.9123\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2494 - accuracy: 0.9148 - val_loss: 0.2475 - val_accuracy: 0.9118\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2449 - accuracy: 0.9167 - val_loss: 0.2466 - val_accuracy: 0.9128\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2408 - accuracy: 0.9180 - val_loss: 0.2426 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2372 - accuracy: 0.9184 - val_loss: 0.2412 - val_accuracy: 0.9126\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2338 - accuracy: 0.9204 - val_loss: 0.2366 - val_accuracy: 0.9148\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2307 - accuracy: 0.9214 - val_loss: 0.2442 - val_accuracy: 0.9108\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2276 - accuracy: 0.9219 - val_loss: 0.2402 - val_accuracy: 0.9131\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2251 - accuracy: 0.9235 - val_loss: 0.2419 - val_accuracy: 0.9148\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2220 - accuracy: 0.9244 - val_loss: 0.2416 - val_accuracy: 0.9128\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2195 - accuracy: 0.9243 - val_loss: 0.2291 - val_accuracy: 0.9170\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2170 - accuracy: 0.9257 - val_loss: 0.2305 - val_accuracy: 0.9168\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_crossentropy\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 25ms/step - loss: 0.8648 - accuracy: 0.5200 - val_loss: 0.7024 - val_accuracy: 0.5811\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6373 - accuracy: 0.6250 - val_loss: 0.5453 - val_accuracy: 0.7333\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4965 - accuracy: 0.7750 - val_loss: 0.4552 - val_accuracy: 0.8225\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8600 - val_loss: 0.3876 - val_accuracy: 0.8641\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.8950 - val_loss: 0.3353 - val_accuracy: 0.9016\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2989 - accuracy: 0.9000 - val_loss: 0.2957 - val_accuracy: 0.9199\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2619 - accuracy: 0.9300 - val_loss: 0.2648 - val_accuracy: 0.9300\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2324 - accuracy: 0.9500 - val_loss: 0.2397 - val_accuracy: 0.9442\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2077 - accuracy: 0.9600 - val_loss: 0.2188 - val_accuracy: 0.9574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1867 - accuracy: 0.9750 - val_loss: 0.2013 - val_accuracy: 0.9635\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1697 - accuracy: 0.9750 - val_loss: 0.1863 - val_accuracy: 0.9686\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1555 - accuracy: 0.9750 - val_loss: 0.1742 - val_accuracy: 0.9696\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1428 - accuracy: 0.9750 - val_loss: 0.1635 - val_accuracy: 0.9726\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9800 - val_loss: 0.1541 - val_accuracy: 0.9726\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9800 - val_loss: 0.1457 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9850 - val_loss: 0.1388 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9900 - val_loss: 0.1323 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 0.9900 - val_loss: 0.1268 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0954 - accuracy: 0.9900 - val_loss: 0.1217 - val_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0901 - accuracy: 0.9950 - val_loss: 0.1164 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,158\n",
      "Trainable params: 276,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc68740b5a361f49f919db40662e49dc14f1db2faacb54b7aeaa4a905f3252ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
